{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465326b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304bf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using numpy backend\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "\n",
    "import geomstats.backend as gs\n",
    "from geomstats.geometry.stiefel import StiefelCanonicalMetric\n",
    "\n",
    "import pymanopt\n",
    "from pymanopt import Problem\n",
    "from pymanopt.manifolds.stiefel import Stiefel\n",
    "from pymanopt.solvers import SteepestDescent, TrustRegions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f05adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "eig_val = 3\n",
    "c1 = gs.eye(eig_val)\n",
    "print(type(c1))\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = StiefelCanonicalMetric(n=eig_val, p=eig_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357b4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autograd.numpy.numpy_boxes.ArrayBox'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sqdist(X):\n",
    "    print(type(X))\n",
    "    return metric.squared_dist(X._value, c1)\n",
    "\n",
    "grad_sqdist = grad(sqdist)\n",
    "grad_sqdist(c1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8919136",
   "metadata": {},
   "source": [
    "# Proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620ac40",
   "metadata": {},
   "source": [
    "Consider the function: $f: St(p, p) \\rightarrow \\mathbb{R}$ defined by:\n",
    "$$f(X) = d^2(X, C_1)$$\n",
    "where $d^2$ is the squared geodesic distance associated with the canonical Riemannian metric on the Stiefel manifold $St(p, p)$.\n",
    "\n",
    "The gradient of $f$ at $X \\in St(p, p)$ is an element of $T_X(St(p, p))$ and defined as:\n",
    "$$\\nabla_Xf = - 2 . \\text{Log}_X(C_1),$$\n",
    "where Log is the Riemannian logarithm associated with the canonical Riemannian metric on the Stiefel manifold $St(p, p)$.\n",
    "\n",
    "We can provide this gradient in closed form when minimizing the function $f$ using `pymanopt`, as in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94013f0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " iter\t\t   cost val\t    grad. norm\n",
      "    1\t+5.7397101018431238e+00\t6.77625861e+00\n",
      "    2\t+3.1547241959023098e+00\t5.02372308e+00\n",
      "    3\t+6.4726581459688703e-01\t2.27554972e+00\n",
      "    4\t+2.3397329703573749e-01\t1.36813244e+00\n",
      "    5\t+5.4526899713703406e-02\t6.60465894e-01\n",
      "    6\t+1.9787028762498864e-02\t3.97864588e-01\n",
      "    7\t+1.0002160451138860e-02\t2.82873264e-01\n",
      "    8\t+7.8905132825875594e-06\t7.94506805e-03\n",
      "    9\t+4.4218437209285152e-07\t1.88081764e-03\n",
      "   10\t+1.2331537572125891e-09\t9.93238645e-05\n",
      "   11\t+1.9415446392991809e-10\t3.94111115e-05\n",
      "   12\t+2.2161637619295751e-11\t1.33151455e-05\n",
      "   13\t+1.9590693073327987e-11\t1.25190073e-05\n",
      "   14\t+1.4786196511006190e-11\t1.08761010e-05\n",
      "   15\t+6.7383338360276426e-12\t7.34211623e-06\n",
      "   16\t+2.5449449056077943e-13\t1.42686927e-06\n",
      "   17\t+8.9291487757510406e-14\t8.45181579e-07\n",
      "Terminated - min grad norm reached after 17 iterations, 0.32 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) Instantiate a manifold\n",
    "manifold = Stiefel(eig_val, eig_val)\n",
    "\n",
    "# (2) Define the cost function (here using autograd.numpy)\n",
    "\n",
    "@pymanopt.function.Autograd\n",
    "def cost(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        return metric.squared_dist(X, c1)\n",
    "    else:\n",
    "        return metric.squared_dist(X._value, c1)\n",
    "       \n",
    "@pymanopt.function.Autograd\n",
    "def custom_grad(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        return -2. * metric.log(base_point=X, point=c1)\n",
    "    else:\n",
    "        return -2. * metric.log(base_point=X._value, point=c1)\n",
    "\n",
    "problem = Problem(manifold=manifold, cost=cost, grad=custom_grad, verbosity=2)\n",
    "\n",
    "# (3) Instantiate a Pymanopt solver\n",
    "solver = SteepestDescent(logverbosity=2)\n",
    "\n",
    "# let Pymanopt do the rest\n",
    "res = solver.solve(problem, x=manifold.rand())\n",
    "Xopt = res[0]\n",
    "\n",
    "#print(Xopt.shape)\n",
    "#display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d243f75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.453648507536602e-14\n"
     ]
    }
   ],
   "source": [
    "print(metric.squared_dist(Xopt, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea06a830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.199839258212869\n"
     ]
    }
   ],
   "source": [
    "print(metric.squared_dist(manifold.rand(), c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d629d",
   "metadata": {},
   "source": [
    "# General case with the cost of Eq. (8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab714b17",
   "metadata": {},
   "source": [
    "In the general case, the function that we seek to minimize is $F: St(p, p)^{n-1} \\rightarrow \\mathbb{R}$ defined on $n-1$ copies of the Stiefel manifold $St(p, p) \\times ... \\times St(p, p)=St(p, p)^{n-1}$ as:\n",
    "$$F(\\mathbf{C}) = F(C_2, ..., C_n) = \\sum_{i, j \\in \\mathcal{E}} d^2(C_i^{-1}.C_j, C_{ij}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b753b07",
   "metadata": {},
   "source": [
    "We want to derive $F$ as a function of $\\mathbf{C} \\in St(p, p)^{n-1}$, where $\\mathbf{C}$ has shape $(n-1) \\times (n-1)p$ that is taking values in $\\mathbb{R}$. The gradient of $F$ at $\\mathbf{C}_0$, written $\\nabla_{\\mathbf{C}_0}F$ can be represented as matrix of shape $(n-1)p \\times (n-1)$ as:\n",
    "$$\\nabla_{\\mathbf{C}_0}F \n",
    "= \\frac{\\partial F}{\\partial \\mathbf{C}}(\\mathbf{C}_0)\n",
    "= \\begin{pmatrix}\n",
    "\\frac{\\partial F}{\\partial C_2}(\\mathbf{C}_0)\\\\\n",
    "...\\\\\n",
    "\\frac{\\partial F}{\\partial C_n}(\\mathbf{C}_0)\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948e462",
   "metadata": {},
   "source": [
    "Thus, we compute each $\\frac{\\partial F}{\\partial C_k}(\\mathbf{C}_0)$, for $k \\in \\{2, ..., n\\}.$\n",
    "\n",
    "We have:\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial F}{\\partial C_k}(\\mathbf{C}_0)\n",
    "&= \\frac{\\partial}{\\partial C_k} \\left(\n",
    "    \\sum_{i, j \\in \\mathcal{E}} d^2(C_i^{-1}.C_j, C_{ij})\\right)(\n",
    "        \\mathbf{C}_0)\\\\\n",
    "&= \\frac{\\partial}{\\partial C_k}\\left(\n",
    "    \\sum_{j \\text{ linked to } k }d^2(C_k^{-1}.C_j, C_{kj}) \n",
    "    + \\sum_{i \\text{ linked to } k } d^2(C_i^{-1}.C_k, C_{ki})\\right)(\n",
    "        \\mathbf{C}_0)\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86803753",
   "metadata": {},
   "source": [
    "Thus, we need to define the derivates of the functions $g_j: St(p, p)\\rightarrow \\mathbb{R}$ defined as:\n",
    "$$g_j(C_k) = d^2(C_k^{-1}.C_j, C_{kj},$$\n",
    "\n",
    "and of the functions $h_i: St(p, p)\\rightarrow \\mathbb{R}$ defined as:\n",
    "$$h_i(C_k) = d^2(C_i^{-1}.C_k, C_{ki}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0981de8",
   "metadata": {},
   "source": [
    "The derivative of the $h_i$ at $\\mathbf{C}_0$ is defined as:\n",
    "$$\\nabla_{\\mathbf{C}_0}h_i \n",
    "= - 2 . (C_{i0}^{-T}) . \\text{Log}_{C_{i0}^{-1}C_{k0}}C_{ki}\n",
    "= - 2 . C_{i0} . \\text{Log}_{C_{i0}^{-1}C_{k0}}C_{ki}$$\n",
    "\n",
    "See:\n",
    "- https://math.stackexchange.com/questions/1377457/how-to-get-the-derivative-of-a-matrix-function\n",
    "- and the book \"The matrix cookbook\" available freely online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b59806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
